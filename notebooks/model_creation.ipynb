{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/train_sample_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "statuses = np.unique(df['OpenStatus'].values)\n",
    "\n",
    "id2label = {idx: label for idx, label in enumerate(statuses)}\n",
    "label2id = {label: idx for idx, label in enumerate(statuses)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from custom_dataset import GithubDataset\n",
    "from torch.utils.data import random_split\n",
    "from datasets import Dataset\n",
    "\n",
    "# Create the pytorch dataset\n",
    "full_dataset = GithubDataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, validation_dataset, test_dataset = random_split(full_dataset, [0.7, 0.25, 0.05])\n",
    "\n",
    "train_dataset = Dataset.from_dict(train_dataset[:])\n",
    "validation_dataset = Dataset.from_dict(validation_dataset[:])\n",
    "test_dataset = Dataset.from_dict(test_dataset[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.rename_columns({\"text_content\": \"text\", \"status\": \"label\"})\n",
    "validation_dataset = validation_dataset.rename_columns({\"text_content\": \"text\", \"status\": \"label\"})\n",
    "test_dataset = test_dataset.rename_columns({\"text_content\": \"text\", \"status\": \"label\"})\n",
    "\n",
    "columns_to_remove = [\n",
    "  'tags_onehot',\n",
    "  'unrecognized_tags_count',\n",
    "  'reputation',\n",
    "  'undeleted_answers',\n",
    "  'user_life_days',\n",
    "  'title'\n",
    "]\n",
    "\n",
    "train_dataset = train_dataset.remove_columns(columns_to_remove)\n",
    "validation_dataset = validation_dataset.remove_columns(columns_to_remove)\n",
    "test_dataset = test_dataset.remove_columns(columns_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting With Different Model Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMMENT - IDEAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We probably should:\n",
    "- retrain the whole model (probably smaller) with\n",
    "- better tokenizer - built up from the ground including all the names of the specific tech (languages, frameworks, IDEs, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TEXT_CONTENT = 128\n",
    "\n",
    "def tokenize_func(batch):\n",
    "  tokenized_batch = tokenizer(batch['text'], padding=True, truncation=True, max_length=MAX_TEXT_CONTENT, return_tensors=\"pt\")\n",
    "  tokenized_batch[\"label\"] = [label2id[label] for label in batch[\"label\"]]\n",
    "  return tokenized_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/98191 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 98191/98191 [00:14<00:00, 6962.42 examples/s]\n",
      "Map: 100%|██████████| 35068/35068 [00:05<00:00, 6789.55 examples/s]\n",
      "Map: 100%|██████████| 7013/7013 [00:01<00:00, 6404.38 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(tokenize_func, batched=True)\n",
    "tokenized_validation_dataset = validation_dataset.map(tokenize_func, batched=True)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text', 'label', 'input_ids', 'attention_mask']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_dataset.column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "  predictions, labels = eval_pred\n",
    "  predictions = np.argmax(predictions, axis=1)\n",
    "  return accuracy_metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Single Text Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# model_content = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=len(statuses), id2label=id2label, label2id=label2id)\n",
    "# # model_content.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "\n",
    "# data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#   output_dir=\"text_content_model\",\n",
    "#   learning_rate=2e-5,\n",
    "#   per_device_train_batch_size=16,\n",
    "#   per_device_eval_batch_size=16,\n",
    "#   num_train_epochs=5,\n",
    "#   weight_decay=0.01,\n",
    "#   evaluation_strategy=\"epoch\",\n",
    "#   save_strategy=\"epoch\",\n",
    "#   load_best_model_at_end=True,\n",
    "# )\n",
    "\n",
    "# trainer = Trainer(\n",
    "#   model=model_content,\n",
    "#   args=training_args,\n",
    "#   train_dataset=tokenized_train_dataset,\n",
    "#   eval_dataset=tokenized_test_dataset,\n",
    "#   tokenizer=tokenizer,\n",
    "#   data_collator=data_collator,\n",
    "#   compute_metrics=compute_metrics,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import TrainerCallback\n",
    "# from copy import deepcopy\n",
    "\n",
    "# class CustomCallback(TrainerCallback):\n",
    "  \n",
    "#   def __init__(self, trainer) -> None:\n",
    "#     super().__init__()\n",
    "#     self._trainer = trainer\n",
    "  \n",
    "#   def on_epoch_end(self, args, state, control, **kwargs):\n",
    "#     if control.should_evaluate:\n",
    "#       control_copy = deepcopy(control)\n",
    "#       self._trainer.evaluate(eval_dataset=self._trainer.train_dataset, metric_key_prefix=\"train\")\n",
    "#       return control_copy\n",
    "\n",
    "# trainer.add_callback(CustomCallback(trainer)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train('./text_content_model/checkpoint-6576')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - Custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from custom_model import AutoCompositeModel \n",
    "model = AutoCompositeModel(device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 7013\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0384,  0.0590, -0.0705, -0.0922, -0.1549, -0.0281, -0.0006, -0.0087,\n",
      "         -0.1026, -0.0106, -0.1685,  0.0502,  0.0094,  0.0354,  0.0776, -0.0419,\n",
      "          0.0198, -0.0838, -0.0385,  0.0493, -0.0382,  0.1712,  0.0100,  0.2353,\n",
      "         -0.0014, -0.0117,  0.0043, -0.0644, -0.0830, -0.0382,  0.0674, -0.0242,\n",
      "          0.0438,  0.0072,  0.0861, -0.0032, -0.0548,  0.0469, -0.0041, -0.0278,\n",
      "         -0.0895, -0.0168, -0.0706, -0.0134,  0.0678,  0.0479,  0.0430,  0.0545,\n",
      "         -0.0979,  0.0881,  0.0892, -0.1212, -0.0217, -0.0655, -0.0575, -0.1099,\n",
      "          0.0451, -0.0932, -0.0943,  0.1754,  0.0437, -0.0225,  0.1049,  0.0773]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.1834, -0.0292, -0.1803,  0.1453, -0.0704]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1834, -0.0292, -0.1803,  0.1453, -0.0704]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainer.predict(tokenized_test_dataset[0])\n",
    "inputs = torch.tensor([tokenized_test_dataset['input_ids'][0]]).to(device)\n",
    "output = model(inputs)\n",
    "output\n",
    "# model_content(tokenized_test_dataset['input_ids'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
