{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/train_sample_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "statuses = np.unique(df['OpenStatus'].values)\n",
    "\n",
    "id2label = {idx: label for idx, label in enumerate(statuses)}\n",
    "label2id = {label: idx for idx, label in enumerate(statuses)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from custom_dataset import GithubDataset\n",
    "from torch.utils.data import random_split\n",
    "from datasets import Dataset\n",
    "\n",
    "# Create the pytorch dataset\n",
    "full_dataset = GithubDataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, validation_dataset, test_dataset = random_split(full_dataset, [0.7, 0.25, 0.05])\n",
    "\n",
    "train_dataset = Dataset.from_dict(train_dataset[:])\n",
    "validation_dataset = Dataset.from_dict(validation_dataset[:])\n",
    "test_dataset = Dataset.from_dict(test_dataset[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming_dict = {\"text_content\": \"text\", \"status\": \"label\"}\n",
    "renaming_dict = {\"status\": \"labels\"}\n",
    "\n",
    "train_dataset = train_dataset.rename_columns(renaming_dict)\n",
    "validation_dataset = validation_dataset.rename_columns(renaming_dict)\n",
    "test_dataset = test_dataset.rename_columns(renaming_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# content_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "# titles_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "import en_core_web_sm\n",
    "tokenizer = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTENT_MAX_TEXT_CONTENT = 128\n",
    "# TITLE_MAX_TEXT_CONTENT = 32\n",
    "\n",
    "# def tokenize_func(batch):\n",
    "#   tokenized_batch = batch\n",
    "#   tokenized_batch['content_input_ids'] = tokenizer(batch['text_content'], padding=True, truncation=True, max_length=CONTENT_MAX_TEXT_CONTENT, return_tensors=\"pt\")['input_ids']\n",
    "  \n",
    "#   tokenized_batch['title_input_ids'] = tokenizer(batch['title'], padding=True, truncation=True, max_length=TITLE_MAX_TEXT_CONTENT, return_tensors=\"pt\")['input_ids']\n",
    "#   tokenized_batch[\"labels\"] = [label2id[label] for label in batch[\"labels\"]]\n",
    "#   return tokenized_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTENT_MAX_TEXT_CONTENT = 128\n",
    "TITLE_MAX_TEXT_CONTENT = 32\n",
    "\n",
    "def tokenize_func(elem):\n",
    "  tokenized_batch = dict()\n",
    "  \n",
    "  tokenized_batch['content_input_ids'] = tokenizer(elem['text_content'])\n",
    "  tokenized_batch['title_input_ids'] = tokenizer(elem['title'])\n",
    "    \n",
    "  # tokenized_batch['content_input_ids'] = tokenizer(batch['text_content'], padding=True, truncation=True, max_length=CONTENT_MAX_TEXT_CONTENT, return_tensors=\"pt\")['input_ids']\n",
    "  \n",
    "  # tokenized_batch['title_input_ids'] = tokenizer(batch['title'], padding=True, truncation=True, max_length=TITLE_MAX_TEXT_CONTENT, return_tensors=\"pt\")['input_ids']\n",
    "  \n",
    "  tokenized_batch[\"labels\"] = label2id[elem['labels']]\n",
    "  return tokenized_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 250/98191 [00:13<1:29:06, 18.32 examples/s]\n"
     ]
    },
    {
     "ename": "ArrowInvalid",
     "evalue": "Could not convert Hey guys, I'm trying to make a 2D Platform style game similar to this game below:\r\n\r\nhttp://www.gameshed.com/Puzzle-Games/Blockdude/play.html\r\n\r\nI have finished making most of the graphic, and areas, and collision, but our character is still not able to carry things. I'm confused as to what code to use so that my character can carry the blocks. I need help as to how to make our character carry blocks that are in front of him, provided that the blocks that don't have anything on top of it. This has been confusing me for a week now, and any help would be highly appreciated. :D with type spacy.tokens.doc.Doc: did not recognize Python value type when inferring an Arrow data type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Pawel\\anaconda3\\envs\\env_torch\\lib\\site-packages\\datasets\\arrow_dataset.py:3442\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3441\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[1;32m-> 3442\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m update_data:\n",
      "File \u001b[1;32mc:\\Users\\Pawel\\anaconda3\\envs\\env_torch\\lib\\site-packages\\datasets\\arrow_dataset.py:3345\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[1;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[0;32m   3344\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[1;32m-> 3345\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m function(\u001b[38;5;241m*\u001b[39mfn_args, \u001b[38;5;241m*\u001b[39madditional_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_kwargs)\n\u001b[0;32m   3346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n",
      "Cell \u001b[1;32mIn[214], line 7\u001b[0m, in \u001b[0;36mtokenize_func\u001b[1;34m(elem)\u001b[0m\n\u001b[0;32m      5\u001b[0m tokenized_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m----> 7\u001b[0m tokenized_batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent_input_ids\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43melem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext_content\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m tokenized_batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle_input_ids\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m tokenizer(elem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Pawel\\anaconda3\\envs\\env_torch\\lib\\site-packages\\spacy\\language.py:1049\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1049\u001b[0m     doc \u001b[38;5;241m=\u001b[39m proc(doc, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcomponent_cfg\u001b[38;5;241m.\u001b[39mget(name, {}))  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Pawel\\anaconda3\\envs\\env_torch\\lib\\site-packages\\spacy\\pipeline\\attributeruler.py:142\u001b[0m, in \u001b[0;36mAttributeRuler.__call__\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 142\u001b[0m     matches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_annotations(doc, matches)\n",
      "File \u001b[1;32mc:\\Users\\Pawel\\anaconda3\\envs\\env_torch\\lib\\site-packages\\spacy\\pipeline\\attributeruler.py:151\u001b[0m, in \u001b[0;36mAttributeRuler.match\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# Sort by the attribute ID, so that later rules have precedence\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m matches \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    152\u001b[0m     (\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab\u001b[38;5;241m.\u001b[39mstrings[m_id]), m_id, s, e) \u001b[38;5;28;01mfor\u001b[39;00m m_id, s, e \u001b[38;5;129;01min\u001b[39;00m matches  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    153\u001b[0m ]\n\u001b[0;32m    154\u001b[0m matches\u001b[38;5;241m.\u001b[39msort()\n",
      "File \u001b[1;32mc:\\Users\\Pawel\\anaconda3\\envs\\env_torch\\lib\\site-packages\\spacy\\pipeline\\attributeruler.py:151\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# Sort by the attribute ID, so that later rules have precedence\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m matches \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    152\u001b[0m     (\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab\u001b[38;5;241m.\u001b[39mstrings[m_id]), m_id, s, e) \u001b[38;5;28;01mfor\u001b[39;00m m_id, s, e \u001b[38;5;129;01min\u001b[39;00m matches  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    153\u001b[0m ]\n\u001b[0;32m    154\u001b[0m matches\u001b[38;5;241m.\u001b[39msort()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Pawel\\anaconda3\\envs\\env_torch\\lib\\site-packages\\datasets\\arrow_writer.py:190\u001b[0m, in \u001b[0;36mTypedSequence.__arrow_array__\u001b[1;34m(self, type)\u001b[0m\n\u001b[0;32m    189\u001b[0m     trying_cast_to_python_objects \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 190\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to_python_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monly_1d_for_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# use smaller integer precisions if possible\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Pawel\\anaconda3\\envs\\env_torch\\lib\\site-packages\\pyarrow\\array.pxi:320\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Pawel\\anaconda3\\envs\\env_torch\\lib\\site-packages\\pyarrow\\array.pxi:39\u001b[0m, in \u001b[0;36mpyarrow.lib._sequence_to_array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Pawel\\anaconda3\\envs\\env_torch\\lib\\site-packages\\pyarrow\\error.pxi:144\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Pawel\\anaconda3\\envs\\env_torch\\lib\\site-packages\\pyarrow\\error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowInvalid\u001b[0m: Could not convert Hey guys, I'm trying to make a 2D Platform style game similar to this game below:\r\n\r\nhttp://www.gameshed.com/Puzzle-Games/Blockdude/play.html\r\n\r\nI have finished making most of the graphic, and areas, and collision, but our character is still not able to carry things. I'm confused as to what code to use so that my character can carry the blocks. I need help as to how to make our character carry blocks that are in front of him, provided that the blocks that don't have anything on top of it. This has been confusing me for a week now, and any help would be highly appreciated. :D with type spacy.tokens.doc.Doc: did not recognize Python value type when inferring an Arrow data type",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[215], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tokenized_train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenize_func\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Pawel\\anaconda3\\envs\\env_torch\\lib\\site-packages\\datasets\\arrow_dataset.py:591\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    590\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 591\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    592\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Pawel\\anaconda3\\envs\\env_torch\\lib\\site-packages\\datasets\\arrow_dataset.py:556\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    549\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    554\u001b[0m }\n\u001b[0;32m    555\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 556\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    557\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    558\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Pawel\\anaconda3\\envs\\env_torch\\lib\\site-packages\\datasets\\arrow_dataset.py:3089\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3083\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mtqdm(\n\u001b[0;32m   3084\u001b[0m         disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mis_progress_bar_enabled(),\n\u001b[0;32m   3085\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3086\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[0;32m   3087\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3088\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3089\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[0;32m   3090\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[0;32m   3091\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Pawel\\anaconda3\\envs\\env_torch\\lib\\site-packages\\datasets\\arrow_dataset.py:3497\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m update_data:\n\u001b[0;32m   3496\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 3497\u001b[0m         \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3498\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tmp_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3499\u001b[0m         tmp_file\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\Pawel\\anaconda3\\envs\\env_torch\\lib\\site-packages\\datasets\\arrow_writer.py:587\u001b[0m, in \u001b[0;36mArrowWriter.finalize\u001b[1;34m(self, close_stream)\u001b[0m\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;66;03m# Re-intializing to empty list for next batch\u001b[39;00m\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhkey_record \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 587\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_examples_on_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;66;03m# If schema is known, infer features even if no examples were written\u001b[39;00m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpa_writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema:\n",
      "File \u001b[1;32mc:\\Users\\Pawel\\anaconda3\\envs\\env_torch\\lib\\site-packages\\datasets\\arrow_writer.py:449\u001b[0m, in \u001b[0;36mArrowWriter.write_examples_on_file\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    445\u001b[0m         batch_examples[col] \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m             row[\u001b[38;5;241m0\u001b[39m][col]\u001b[38;5;241m.\u001b[39mto_pylist()[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(row[\u001b[38;5;241m0\u001b[39m][col], (pa\u001b[38;5;241m.\u001b[39mArray, pa\u001b[38;5;241m.\u001b[39mChunkedArray)) \u001b[38;5;28;01melse\u001b[39;00m row[\u001b[38;5;241m0\u001b[39m][col]\n\u001b[0;32m    447\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_examples\n\u001b[0;32m    448\u001b[0m         ]\n\u001b[1;32m--> 449\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_examples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_examples \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Pawel\\anaconda3\\envs\\env_torch\\lib\\site-packages\\datasets\\arrow_writer.py:556\u001b[0m, in \u001b[0;36mArrowWriter.write_batch\u001b[1;34m(self, batch_examples, writer_batch_size)\u001b[0m\n\u001b[0;32m    554\u001b[0m         col_try_type \u001b[38;5;241m=\u001b[39m try_features[col] \u001b[38;5;28;01mif\u001b[39;00m try_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m try_features \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    555\u001b[0m         typed_sequence \u001b[38;5;241m=\u001b[39m OptimizedTypedSequence(col_values, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mcol_type, try_type\u001b[38;5;241m=\u001b[39mcol_try_type, col\u001b[38;5;241m=\u001b[39mcol)\n\u001b[1;32m--> 556\u001b[0m         arrays\u001b[38;5;241m.\u001b[39mappend(\u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyped_sequence\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    557\u001b[0m         inferred_features[col] \u001b[38;5;241m=\u001b[39m typed_sequence\u001b[38;5;241m.\u001b[39mget_inferred_type()\n\u001b[0;32m    558\u001b[0m schema \u001b[38;5;241m=\u001b[39m inferred_features\u001b[38;5;241m.\u001b[39marrow_schema \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpa_writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema\n",
      "File \u001b[1;32mc:\\Users\\Pawel\\anaconda3\\envs\\env_torch\\lib\\site-packages\\pyarrow\\array.pxi:236\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Pawel\\anaconda3\\envs\\env_torch\\lib\\site-packages\\pyarrow\\array.pxi:110\u001b[0m, in \u001b[0;36mpyarrow.lib._handle_arrow_array_protocol\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Pawel\\anaconda3\\envs\\env_torch\\lib\\site-packages\\datasets\\arrow_writer.py:254\u001b[0m, in \u001b[0;36mTypedSequence.__arrow_array__\u001b[1;34m(self, type)\u001b[0m\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m trying_cast_to_python_objects \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n\u001b[1;32m--> 254\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to_python_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monly_1d_for_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize_list_casting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    256\u001b[0m         out \u001b[38;5;241m=\u001b[39m cast_array_to_feature(out, \u001b[38;5;28mtype\u001b[39m, allow_number_to_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Pawel\\anaconda3\\envs\\env_torch\\lib\\site-packages\\pyarrow\\array.pxi:320\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Pawel\\anaconda3\\envs\\env_torch\\lib\\site-packages\\pyarrow\\array.pxi:39\u001b[0m, in \u001b[0;36mpyarrow.lib._sequence_to_array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Pawel\\anaconda3\\envs\\env_torch\\lib\\site-packages\\pyarrow\\error.pxi:144\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Pawel\\anaconda3\\envs\\env_torch\\lib\\site-packages\\pyarrow\\error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowInvalid\u001b[0m: Could not convert Hey guys, I'm trying to make a 2D Platform style game similar to this game below:\r\n\r\nhttp://www.gameshed.com/Puzzle-Games/Blockdude/play.html\r\n\r\nI have finished making most of the graphic, and areas, and collision, but our character is still not able to carry things. I'm confused as to what code to use so that my character can carry the blocks. I need help as to how to make our character carry blocks that are in front of him, provided that the blocks that don't have anything on top of it. This has been confusing me for a week now, and any help would be highly appreciated. :D with type spacy.tokens.doc.Doc: did not recognize Python value type when inferring an Arrow data type"
     ]
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(tokenize_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/98191 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 98191/98191 [00:17<00:00, 5724.80 examples/s]\n",
      "Map: 100%|██████████| 35068/35068 [00:05<00:00, 5967.95 examples/s]\n",
      "Map: 100%|██████████| 7013/7013 [00:01<00:00, 5960.71 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(tokenize_func, batched=True)\n",
    "tokenized_validation_dataset = validation_dataset.map(tokenize_func, batched=True)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_train_dataset['title_input_ids'][11])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tags_onehot', 'unrecognized_tags_count', 'reputation', 'undeleted_answers', 'user_life_days', 'title', 'text_content', 'labels', 'content_input_ids', 'title_input_ids'],\n",
       "    num_rows: 7013\n",
       "})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_test_dataset\n",
    "# tokenized_test_dataset['user_life_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = [\n",
    "  'tags_onehot',\n",
    "  'unrecognized_tags_count',\n",
    "  # 'reputation',\n",
    "  # 'undeleted_answers',\n",
    "  # 'user_life_days',\n",
    "  'title',\n",
    "  'text_content',\n",
    "]\n",
    "\n",
    "tokenized_train_dataset = tokenized_train_dataset.remove_columns(columns_to_remove)\n",
    "tokenized_validation_dataset = tokenized_validation_dataset.remove_columns(columns_to_remove)\n",
    "tokenized_test_dataset = tokenized_test_dataset.remove_columns(columns_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMMENT - IDEAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We probably should:\n",
    "- retrain the whole model (probably smaller) with\n",
    "- better tokenizer - built up from the ground including all the names of the specific tech (languages, frameworks, IDEs, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_model import AutoCompositeModel\n",
    "\n",
    "model = AutoCompositeModel(device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features = [\n",
    "  'content_input_ids',\n",
    "  'title_input_ids',\n",
    "  'labels',\n",
    "]\n",
    "\n",
    "def collate_func(batch):\n",
    "  # test = 0\n",
    "  # print(batch)\n",
    "  \n",
    "  # all = batch[:]\n",
    "  # test = [all[feature] for feature in important_features]\n",
    "  print(batch[0]['title_input_ids'])\n",
    "  print(batch[1]['title_input_ids'])\n",
    "  \n",
    "  print(len(batch[0]['title_input_ids']))\n",
    "  print(len(batch[1]['title_input_ids']))\n",
    "  return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "training_loader = DataLoader(tokenized_train_dataset, batch_size=16, shuffle=True, collate_fn=collate_func)\n",
    "validation_loader = DataLoader(tokenized_validation_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(tokenized_test_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1039, 1001, 1012, 5658, 1006, 18847, 1007, 5443, 9262, 5443, 18106, 2250, 1006, 2004, 2509, 1007, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 16770, 2128, 15549, 3064, 2005, 1042, 2497, 3931, 21628, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "41\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(training_loader):\n",
    "  if i >= 0:\n",
    "    break\n",
    "    \n",
    "  # print(data[1]['title_input_ids'])\n",
    "  # print(len(data[1]['title_input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 6575, 1999, 2004, 2361, 4438, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_dataset['title_input_ids'][0])\n",
    "print(len(tokenized_train_dataset['title_input_ids'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, data in enumerate(training_loader):\n",
    "#   if i < 1:\n",
    "#     print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers specified in the torch.optim package\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, weight_decay=1e-5, momentum=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "\n",
    "accuracy_metric = Accuracy(task='multiclass', num_classes=5).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_own import Trainer, TrainerConfiguration, get_model_params\n",
    "\n",
    "config = TrainerConfiguration(\n",
    "  training_loader=training_loader,\n",
    "  validation_loader=validation_loader,\n",
    "  optimizer=optimizer,\n",
    "  loss_fn=loss_fn,\n",
    "  accuracy_metric=accuracy_metric,\n",
    "  device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "692933"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model, trainer_configuration=config, input_columns=['content_input_ids', 'title_input_ids', 'reputation', 'undeleted_answers', 'user_life_days'], output_column='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6137"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "column_name content_input_ids\n",
      "inputs[column_name] [tensor([  101,  1045,  1005,  1049,  2667,  2000,  2131,  1996,  5798,  3200,\n",
      "         2013, 19557, 14141,  8303,  8654,  2006,  2026, 18059,  1012,  1045,\n",
      "         1005,  2310,  2246,  2083,  2070, 10287,  2058,  1996,  4773,  1998,\n",
      "         3262, 26021,  1996,  2168,  3437,  1010,  2029,  1045,  2031,  2699,\n",
      "         2870,  2004,  2917,  1012,  2021,  2023,  2145,  2987,  1005,  1056,\n",
      "         2147,  2005,  2033,  2061,  1045,  4687,  2065,  1045,  4771,  2242,\n",
      "         2842,  1012,  1012,  1012,  1012,  2154, 14192, 20097,  1027,  1031,\n",
      "         1031,  1031, 24978, 13701, 14192, 20097,  2035, 10085,  1033,  1999,\n",
      "         4183,  1033,  8285, 16570, 19500,  1033,  1025,  1031,  2969,  1012,\n",
      "         2154, 14192, 20097,  2275, 13701, 14192,  4017,  1024,  1030,  1000,\n",
      "        25391,  2213,  1040,  1000,  1033,  1025, 24978,  3367,  4892,  1008,\n",
      "         2651,  1027,  1031,  2154, 14192, 20097,  5164, 19699,  5358, 13701,\n",
      "         1024,  1031, 24978, 13701,  3058,  1033,  1033,   102],\n",
      "       device='cuda:0'), tensor([  101,  2065,  1045,  5425,  2824,  2004,  2027,  2024,  6230,  1006,\n",
      "         1041,  1012,  1043,  1012,  3006,  3976,  2895,  1007,  2007,  1996,\n",
      "        17626,  2005,  1996,  4353,  2000,  2022,  1037, 11135,  1997,  1037,\n",
      "         3671,  4330,  7774,  2052,  1045,  2022, 15123,  1999,  3241,  2008,\n",
      "         2045,  2052,  2022,  2019,  5056,  2000,  6202,  2004,  2295,  3976,\n",
      "         2895,  2097,  1000,  3671,  4697,  1000,  2065,  2009,  2003,  4895,\n",
      "         7507, 22648,  3334,  6553,  3973,  2025,  4330,  5044,  1029,   102,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0],\n",
      "       device='cuda:0'), tensor([  101,  1045,  2572,  2725,  2019,  8775,  2055, 20704,  2140,  3628,\n",
      "         1999,  9262,  1012,  1045,  2572,  2893,  1037, 19701, 10288, 24422,\n",
      "         7561,  2043,  2667,  2000,  5703,  1996,  3392,  2011,  2965,  1997,\n",
      "         1996,  9963,  2015,  1012,  2064,  2017, 20228,  2015,  2393,  2033,\n",
      "         1999,  4531,  1996,  7561,  1029,  2182,  2003,  2026,  3642,  1024,\n",
      "         2270,  2465, 13045,  1063,  2797, 20014,  3643,  1025,  2797, 13045,\n",
      "         2187,  3630,  3207,  1025,  2797, 13045,  2157,  3630,  3207,  1025,\n",
      "         2270, 13045,  1006, 20014,  3643,  1007,  1063,  2023,  1012,  3643,\n",
      "         1027,  3643,  1025,  1065,  2270, 13045,  1006,  1007,  1063,  1065,\n",
      "         2270, 13045,  1006, 20014,  3643,  1010, 13045,  2187,  3630,  3207,\n",
      "         1010, 13045,  2157,  3630,  3207,  1007,  1063,  2023,  1012,  3643,\n",
      "         1027,  3643,  1025,  2023,  1012,  2187,  3630,  3207,  1027,  2187,\n",
      "         3630,  3207,  1025,  2023,  1012,  2157,  3630,   102],\n",
      "       device='cuda:0'), tensor([  101,  1045,  1005,  1049,  2667,  2000,  4503,  1013,  3417,  1037,\n",
      "         2208,  2000, 11924,  1010,  2021,  2009,  1005,  1055,  1999,  1039,\n",
      "         1010,  1998, 11924,  6753,  9262,  1010,  2021,  1045,  1005,  1049,\n",
      "         2469,  2045,  2442,  2022,  1037,  2126,  2000,  2131,  1037,  1039,\n",
      "        10439,  2006,  2045,  1010,  3087,  4282,  1997,  1037,  2204, 14924,\n",
      "         4818,  2006,  1996,  3395,  1029,  4283,   999,   102,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0],\n",
      "       device='cuda:0'), tensor([  101,  1045,  4033,  1005,  1056,  2109, 19723, 10288,  2061,  3531,\n",
      "         8016,  2033,  1012,  1012,  1045,  2031,  1037,  5164,  2066,  5164,\n",
      "         5034,  2099,  1027, 16770,  1024,  1013,  1013,  5925,  2063,  1013,\n",
      "         1013,  2026, 22199,  1045,  2215,  2000,  4638,  2065,  1996,  3327,\n",
      "         5164,  2442,  2707,  2007,  1000, 16770,  1024,  1013,  1013,  1000,\n",
      "         1998,  4515,  2007,  1000,  1013,  1013,  2026, 22199,  1000,  2129,\n",
      "         2064,  1045, 12336,  3512,  2008,  1012,  1012,   102,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0],\n",
      "       device='cuda:0'), tensor([  101,  2292,  1005,  1055,  2360,  1045,  2031, 10281,  2066,  2023,\n",
      "         1024,  2034,  1010,  2197,  1010,  4769,  1010,  4769,  1016,  1010,\n",
      "        10373,  1010,  7661,  2487,  1010,  7661,  2475,  1010,  7661,  2509,\n",
      "         1015,  1037,  1010,  1038,  1010,  1039,  1010,  1040,  1010,  1041,\n",
      "         1030,  1041,  1012,  4012,  1010,  1015,  1010,  1016,  1010,  1017,\n",
      "         1016,  1037,  1010,  1010,  1039,  1010,  1040,  1010,  1041,  1030,\n",
      "         1041,  1012,  4012,  1010,  1015,  1010,  1016,  1010,  1017,  1010,\n",
      "         1010,  1010,  1010,  1041,  1030,  1041,  1012,  4012,  1010,  1015,\n",
      "         1010,  1010,  2054,  1045,  2052,  2066,  2000,  2000,  2079,  2003,\n",
      "         3443,  1037,  3853,  2008,  8005,  2008,  5216,  2029,  2003,  2087,\n",
      "         3143,  1998,  1045,  1005,  1049,  6603,  2065,  2045,  2024,  2151,\n",
      "        14555,  2030,  3653,  1011,  4493,  4725,  1006, 11433,  1010,  2130,\n",
      "         1007,  2005,  2725,  2023,  1012,  1999,  1996,   102],\n",
      "       device='cuda:0'), tensor([  101,  2054,  2003,  1996,  2190,  1010,  2110,  1997,  2396,  3921,\n",
      "         2005, 14972, 21641,  4773,  2578,  1029,  1045,  2572,  2559,  2005,\n",
      "         1037,  3143,  4294,  6412,  1012,   102,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0],\n",
      "       device='cuda:0'), tensor([  101,  1008,  1008,  1008,  1008,  1028,  1045,  2001,  2667,  2000,\n",
      "         4339,  1037,  3642,  2000,  7901,  2296,  1047,  3787,  1997,  1037,\n",
      "         5799,  2862,  1012,  1008,  1008,  1028,  1045,  2743,  2046,  2023,\n",
      "         5866,  7561,  2043,  1045,  3046,  2000,  6140,  1996,  2951,  4180,\n",
      "         1997,  2028,  1997,  1996,  1008,  1008,  1028, 13045,  1012,  1008,\n",
      "         1008,  1028,  2342,  2000,  2113,  2339,  2023,  2003,  6230,  1012,\n",
      "         1008,  1008,  1028,  3531,  2298,  2012,  1996,  7615,  1999,  1996,\n",
      "         7901,  1006,  1007,  3853,  2917,  1008,  1008,  2465,  4957,  1063,\n",
      "        20014,  2951,  1025,  2270,  4957,  2279, 13767,  1025,  4957,  1006,\n",
      "        20014,  1040,  2487,  1007,  1063,  2951,  1027,  1040,  2487,  1025,\n",
      "         1065,  1065,  2465,  2862,  1063,  4957,  2132,  1025, 20014,  5210,\n",
      "         1027,  1014,  1025,  4957,  7065,  4974,  1025,  1013,  1013,  1027,\n",
      "         2132,  1025,  1013,  1013,  7065,  4974,  1027,   102],\n",
      "       device='cuda:0'), tensor([  101,  1045,  2179,  2023,  4037,  2096,  6575,  2005,  2190,  4773,\n",
      "         5617,  1024,  8299,  1024,  1013,  1013,  1996, 13626, 10128,  2102,\n",
      "         8237,  1012,  2522,  1012,  2866,  1013,  1045,  1005,  1040,  2066,\n",
      "         2000,  2131,  2019,  2801,  1997,  2129,  1996, 11216,  1013,  9797,\n",
      "         4719,  1996,  3466,  1997,  4363,  2070,  3787, 10763,  2306,  1037,\n",
      "         2930,  1010,  2066,  1996,  9982,  1010,  2009,  3504,  2062, 10763,\n",
      "         2084,  1996, 14186,  1010,  1998,  1996, 14186,  3711,  2000,  2693,\n",
      "         2004,  1045, 17186,  2091,  1012,  2036,  1010,  2129,  2000,  2191,\n",
      "         2019,  3746,  2030,  5783,  2069,  3711,  2306,  1037,  2445,  2930,\n",
      "         1010,  1998,  2059,  2693,  2004,  1045, 17186,  2091,  1006,  1996,\n",
      "        14186,  1998,  5689,  4871,  1997,  2169,  2930,  1010,  2030,  1996,\n",
      "         2712,  2732,  1999,  2028,  6013,  1007,  1998,  1999,  2023,  2060,\n",
      "         4973,  1010,  2029,  3594,  2714,  5461,  1010,   102],\n",
      "       device='cuda:0'), tensor([  101,  1045,  1005,  1049,  2383,  1037,  3291,  4824,  1996,  2832,\n",
      "         1997, 23658,  1996,  6745,  2544,  1997,  2773, 20110,  1017,  1012,\n",
      "         1015,  1012,  1017,  2008,  1045, 22817,  2013,  2773, 20110,  1012,\n",
      "         8917,  1012,  1045,  2106,  3046,  2893,  2393,  2013,  2026,  5799,\n",
      "         2378,  2177,  1998,  2013,  2814,  1010,  2021,  2053, 18740,  1012,\n",
      "         2027,  2106,  3046,  2000,  2393,  1010,  2021,  1045,  2145,  2123,\n",
      "         1005,  1056,  1012,  2009,  1005,  1055,  1037,  2274,  3357,  2832,\n",
      "         1998,  1045,  3305,  1996,  2034,  3357,  1010,  2021,  1996,  2279,\n",
      "         2048,  4084,  2031,  2033,  5457,  1010,  2023,  2003,  2013,  1996,\n",
      "         3191,  4168,  1012, 16129,  5371,  2013,  1996,  2773, 20110, 19622,\n",
      "         2008,  2234,  2007,  1996,  8816,  1024,  1016,  1012,  2330,  1059,\n",
      "         2361,  1011,  4748, 10020,  1013, 16500,  1012, 25718,  1999,  2115,\n",
      "        16602,  1012,  2009,  2097,  2202,  2017,  2083,   102],\n",
      "       device='cuda:0'), tensor([  101,  1045,  3305,  2129,  2000,  2224,  8790,  4013, 16898,  2015,\n",
      "         1999,  9262,  2021,  2054,  1045,  2123,  1005,  1056,  3305,  2003,\n",
      "         2129,  1996,  1058,  2213,  2941,  9005,  1037,  8790, 24540,  1012,\n",
      "         2515,  2009,  9699, 24880, 16044,  1998,  7170,  2009,  1029,  2030,\n",
      "         2242,  2842,  1029,  4283,  1012,   102,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0],\n",
      "       device='cuda:0'), tensor([  101,  2054,  2015,  3308,  2007,  2023,  3642,  1029,  1029, 21933,\n",
      "         8737,  1024,  1024,  5164,  1011,  1028,  5164, 21933,  8737,  1000,\n",
      "         1000,  1027,  1000,  1000, 21933,  8737,  1006,  1060,  1024,  1060,\n",
      "         2015,  1007,  1027,  4654,  2361,  1006,  2139,  1006,  1060,  1024,\n",
      "         1060,  2015,  1007,  4654,  2361, 19884,  1037,  1037,  2862,  1006,\n",
      "        25869,  1010, 20014,  1007,  2000,  1037,  5164,  2107,  2004,  1037,\n",
      "         2629,  2094,  2575,  2097,  6434,  1006,  1037,  1010,  1019,  1007,\n",
      "         1010,  1006,  1040,  1010,  1020,  1007,  1998,  2139, 19884,  1037,\n",
      "         5164,  2046,  1037,  2862,  1997,  1006, 25869,  1010, 20014,  1007,\n",
      "         2107,  2004,  1006,  1037,  1010,  1019,  1007,  1010,  1006,  1040,\n",
      "         1010,  1020,  1007,  2097,  6434, 13360,  4215, 14141, 14141,  2094,\n",
      "         2061, 21933,  8737,  2017,  7953,  1037,  2629,  2094,  2575, 13360,\n",
      "        11057, 14141, 14141, 14141,  4613,  6017, 12421,   102],\n",
      "       device='cuda:0'), tensor([  101,  1045,  2572,  2478,  1046, 22747,  1016,  1012,  1014,  1998,\n",
      "         3500,  1017,  1012,  1014,  1012,  1016,  1998,  3419, 11266,  1021,\n",
      "         1012,  1014,  1012,  2403,  1012,  1014,  2004,  8241,  1012,  1045,\n",
      "         2031,  2019,  3277,  2007,  5278,  2653,  1997,  2026,  2609,  1012,\n",
      "         2035,  1996,  9537,  2024,  2551,  2092,  1999,  2026,  2334,  8241,\n",
      "         1012,  2021,  2043,  1045, 21296,  2006,  8241,  1010,  2653,  3431,\n",
      "         2515,  2025,  3466,  1012,  2049,  8073,  7276,  3304,  2004,  1037,\n",
      "        12398,  2653,  1012,  2043,  1045, 11562,  2006,  2178,  2653,  1010,\n",
      "         2498,  2003,  3431,  1012,  2182,  2003,  2026, 14068,  3642,  1024,\n",
      "         1030,  3266,  4783,  2319,  1006,  2171,  1027,  1000,  2653,  1000,\n",
      "         1007,  1030,  6521, 16186,  2094,  2270,  2465,  2653,  4783,  2319,\n",
      "        22164,  7642, 21335,  3468,  1063,  2797, 10763,  2345,  2146,  7642,\n",
      "        27774, 21272,  1027,  1015,  2140,  1025,  2797,   102],\n",
      "       device='cuda:0'), tensor([  101,  1045,  1005,  2310,  2288,  1037,  8023,  2008,  2071,  2593,\n",
      "         2022,  1037,  5164,  2030,  1037, 10722, 10814,  1006,  1045,  2123,\n",
      "         1005,  1056,  2113,  3805,  1997,  2051,  1007,  1998,  1045,  2342,\n",
      "         2000,  2147,  2007,  2009,  2004,  1037,  2862,  1012,  7687,  1010,\n",
      "         1045,  2215,  2000, 10938,  1996,  2206,  2046,  1037,  2862, 26683,\n",
      "         1012,  8023,  1027,  1005,  8909,  1005,  2345,  1027,  1031,  1033,\n",
      "         2065,  2003,  7076, 26897,  1006,  8023,  1010,  2358,  2099,  1007,\n",
      "         1024,  2345,  1012, 10439, 10497,  1006,  8023,  1007, 12005,  2546,\n",
      "         2003,  7076, 26897,  1006,  8023,  1010, 10722, 10814,  1007,  1024,\n",
      "         2345,  1027,  2862,  1006,  8023,  1007,  1045,  2001,  3241,  2242,\n",
      "         2247,  1996,  3210,  1997,  1996,  2206,  1006,  2029,  3957,  2033,\n",
      "         1037, 20231,  7561,  1007,  1012,  2345,  1027,  1031, 13075,  2005,\n",
      "        13075,  1999,  8023,  2065,  2003,  7076, 26897,   102],\n",
      "       device='cuda:0'), tensor([  101,  1045,  1005,  1049,  2747,  2725,  1037,  2470,  2006,  1008,\n",
      "        19293, 19706,  1008,  1998,  1045,  1005,  1040,  2066,  2000,  2963,\n",
      "         2070, 10960,  2013,  3507,  4773,  9797,  2006,  2023,  3395,  1012,\n",
      "         2057,  2109,  2000,  2031,  1008, 10763, 19706,  1008,  2067,  1999,\n",
      "         1996,  2154,  1010,  2073,  2017,  2481,  2102,  2689,  1037,  2518,\n",
      "         1998,  2017,  2018,  2000,  4553,  1996,  2291,  1996,  2126,  2009,\n",
      "         2001,  3857,  1012,  2044,  2008,  2234,  1008, 15581,  3085, 19706,\n",
      "         1008,  1010,  2073,  2017,  2071,  2689,  2070, 18394,  2000,  1996,\n",
      "         2126,  2017,  2359,  1012,  2228,  1997, 15489,  1011,  2946,  1010,\n",
      "         6087,  1998,  9621,  1012,  2122,  2024,  1996, 19706,  2057,  2156,\n",
      "         3262,  2651,  1012,  1996,  2279,  3357,  1999,  2023,  2181,  1997,\n",
      "         2470,  1998,  2458,  2006, 19706,  2003,  4011,  2000,  2022,  1008,\n",
      "        19293, 19706,  1008,  1012,  1008,  1008,  2019,   102],\n",
      "       device='cuda:0'), tensor([  101,  1045,  2572,  2551,  2006,  1037,  2622,  2256,  4037,  5859,\n",
      "         2435,  2149,  2023,  3642,  2005,  5198,  2000,  4060,  2037,  2344,\n",
      "         1026, 10047,  2290,  5034,  2278,  1027,  1000,  4871,  1013,  4031,\n",
      "         8889,  2487,  1012,  1052,  3070,  1000, 12456,  1027,  1000,  1000,\n",
      "         1013,  1028,  1026,  1044,  2487,  1028,  9686, 20110,  2080, 25043,\n",
      "        26723,  1026,  1013,  1044,  2487,  1028,  1026,  8487,  1028, 25718,\n",
      "        25897,  1012,  5585,  1026,  1013,  8487,  1028,  1026,  6462,  1028,\n",
      "         2344,  1026,  1013,  6462,  1028,  2035,  2057,  2342,  2000,  2079,\n",
      "         2003,  5587,  1037, 25718,  3642,  2000,  2009,  2043,  1037,  5310,\n",
      "        29225,  1996,  6462,  2009,  2097,  4604,  1996,  2344,  2000,  1996,\n",
      "         7809,  1010,  2079,  2017,  2031,  2151,  2801,  2129,  2057,  2024,\n",
      "         2183,  2000,  2079,  2009,  1029,  4283,  1999,  5083,   102,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0],\n",
      "       device='cuda:0')]\n",
      "len(inputs[column_name]) 16\n",
      "len(inputs[column_name][0]) 128\n",
      "len(inputs[column_name][1]) 128\n",
      "column_name title_input_ids\n",
      "inputs[column_name] [tensor([  101, 19557, 14141,  8303,  8654,  2131,  5798,  3200,   102,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "       device='cuda:0'), tensor([  101,  2003,  2009,  2825,  2000,  5468,  1037, 11135,  2004,  2009,\n",
      "         1005,  1055,  4895, 21508,  2000,  2224,  2005, 19939,  2075,  1029,\n",
      "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "       device='cuda:0'), tensor([  101, 19701,  6453,  7561,  1999, 20704,  2140,  3628,   102,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0], device='cuda:0'), tensor([  101,  2129,  2064,  1045,  4339,  5097,  1999,  1039,  2030,  1039,\n",
      "         1009,  1009,  2005, 11924,  1029,   102,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0], device='cuda:0'), tensor([  101,  2129,  2000,  2224, 19723, 10288,  1029,   102,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0], device='cuda:0'), tensor([  101, 10549,  1996,  5216,  2008,  2038,  1996,  2087,  3143,  2592,\n",
      "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0], device='cuda:0'), tensor([  101, 21641,  4773,  2578,   102,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0], device='cuda:0'), tensor([  101, 19701, 20884,  7561,  2006,  2667,  2000,  6140,  1037, 13045,\n",
      "         1997,  1996,  5799,  2862,   102,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0], device='cuda:0'), tensor([ 101, 2129, 2064, 1045, 6162, 1996, 3466, 1997, 2023, 4037, 1012, 1012,\n",
      "        1012,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0], device='cuda:0'), tensor([  101,  8272,  2832,  2005,  2773, 20110,   102,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0], device='cuda:0'), tensor([  101,  2129,  2515,  9262,  1005,  1055,  8790, 24540,  2941,  2147,\n",
      "         1029,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "       device='cuda:0'), tensor([  101,  2129,  2000, 11506,  4972,  1029,  1029,   102,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0],\n",
      "       device='cuda:0'), tensor([  101,  1046, 22747,  2475,  1012,  1014,  1011,  3500,  2653,  2689,\n",
      "         2025,  2551,  2006,  8241,   102,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0], device='cuda:0'), tensor([  101,  1005,  2842,  1005,  4861,  1999,  2862, 26683,  2015,   102,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "       device='cuda:0'), tensor([  101,  1031, 19293, 19706,  1033,  2339,  4995,  1005,  1056,  2027,\n",
      "         2105,  2008,  2172,  1029,   102,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0],\n",
      "       device='cuda:0'), tensor([  101,  2393,  2007, 16129,  6462,  1998, 25718,   102,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0], device='cuda:0')]\n",
      "len(inputs[column_name]) 16\n",
      "len(inputs[column_name][0]) 49\n",
      "len(inputs[column_name][1]) 49\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [49] at entry 0 and [56] at entry 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_many_epochs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluate_when_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Pawel\\Documents\\_projects\\Github-Questions-Classification\\notebooks\\training_own.py:136\u001b[0m, in \u001b[0;36mTrainer.train_many_epochs\u001b[1;34m(self, epochs, logging_frequency, evaluate_when_logging)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEPOCH \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch_number \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Make sure gradient tracking is on, and do a pass over the data\u001b[39;00m\n\u001b[1;32m--> 136\u001b[0m avg_loss, avg_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogging_frequency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluate_when_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluate_when_logging\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m avg_vloss, avg_vacc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_model()\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLOSS train \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m valid \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m ACCURACY train \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m validation \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(avg_loss, avg_vloss, avg_acc, avg_vacc))\n",
      "File \u001b[1;32mc:\\Users\\Pawel\\Documents\\_projects\\Github-Questions-Classification\\notebooks\\training_own.py:72\u001b[0m, in \u001b[0;36mTrainer.train_one_epoch\u001b[1;34m(self, logging_frequency, evaluate_when_logging)\u001b[0m\n\u001b[0;32m     70\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlen(inputs[column_name][1])\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(inputs[column_name][\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m     71\u001b[0m   \u001b[38;5;66;03m# inputs[column_name] = torch.tensor(inputs[column_name])\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m   inputs[column_name] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#.float().to(self.config.device)\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# inputs = torch.stack(data[self.input_columns], 1).float().to(self.config.device) # FIX - .long() etc <- move it to the dataset procesing part. Here, only stack + device\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, inputs)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [49] at entry 0 and [56] at entry 2"
     ]
    }
   ],
   "source": [
    "trainer.train_many_epochs(epochs=8, logging_frequency=100, evaluate_when_logging=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
